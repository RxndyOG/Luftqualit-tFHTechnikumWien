{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spark ML (Jahr-Join): Verkehr ↔ Schadstoffe (Wien) – angepasst auf deine CSVs\n",
        "\n",
        "Dieses Notebook ist für **deine beiden CSV-Exports** gebaut:\n",
        "\n",
        "**Verkehr.csv Header**\n",
        "`_id;NUTS1;NUTS2;NUTS3;DISTRICT_CODE;SUB_DISTRICT_CODE;YEAR;UNIT;REF_YEAR;ROAD_TRAFFIC;SCWR_CALC;_imported_at`\n",
        "\n",
        "**Schadstoff.csv Header**\n",
        "`_id;Region;Schadstoff;Einheit;NFR_Code;Trendbericht_Sektor;Quelle;Datenstand;Jahr; Werte ;_imported_at`\n",
        "\n",
        "Besonderheiten:\n",
        "- Separator: `;`\n",
        "- Zahlenformat kann `.` als Tausender und `,` als Dezimal haben → wird zu `double` gecastet\n",
        "- Kein Timestamp → Join über **YEAR ↔ Jahr**\n",
        "- Schadstoffe: nur **Region == Wien**\n",
        "- Verkehr: ist ohnehin Wien → wir setzen Region-Spalte auf `\"Wien\"`\n",
        "- Fehlende Jahre im Verkehr: Join ist standardmäßig `left` (Schadstoff-Jahre bleiben)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "spark = (SparkSession.builder\n",
        "         .appName(\"air-traffic-year-join-ml\")\n",
        "         .getOrCreate())\n",
        "\n",
        "spark.version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Pfade setzen (CSV)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# HIER ANPASSEN\n",
        "# ---------------------------\n",
        "TRAFFIC_CSV_PATH = \"./export/Verkehr.csv\"\n",
        "AIR_CSV_PATH     = \"./export/Schadstoff.csv\"\n",
        "\n",
        "CSV_SEP = \";\"\n",
        "HAS_HEADER = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) CSV laden (alles als String, dann sauber casten)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "traffic_raw = (spark.read\n",
        "               .option(\"header\", str(HAS_HEADER).lower())\n",
        "               .option(\"sep\", CSV_SEP)\n",
        "               .option(\"inferSchema\", \"false\")\n",
        "               .csv(TRAFFIC_CSV_PATH))\n",
        "\n",
        "air_raw = (spark.read\n",
        "           .option(\"header\", str(HAS_HEADER).lower())\n",
        "           .option(\"sep\", CSV_SEP)\n",
        "           .option(\"inferSchema\", \"false\")\n",
        "           .csv(AIR_CSV_PATH))\n",
        "\n",
        "print(\"traffic rows:\", traffic_raw.count(), \"cols:\", len(traffic_raw.columns))\n",
        "print(\"air rows:\", air_raw.count(), \"cols:\", len(air_raw.columns))\n",
        "\n",
        "traffic_raw.show(5, truncate=False)\n",
        "air_raw.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Spaltennamen trimmen (wichtig wegen ` Werte `)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "traffic_raw = traffic_raw.toDF(*[c.strip() for c in traffic_raw.columns])\n",
        "air_raw = air_raw.toDF(*[c.strip() for c in air_raw.columns])\n",
        "\n",
        "print(\"Traffic columns:\", traffic_raw.columns)\n",
        "print(\"Air columns:\", air_raw.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Helper: deutsches Zahlenformat → double"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def cast_de_number(df, colname: str, to_type=\"double\"):\n",
        "    # '.' als Tausender raus, ',' -> '.'\n",
        "    cleaned = F.regexp_replace(F.col(colname).cast(\"string\"), r\"\\.\", \"\")\n",
        "    cleaned = F.regexp_replace(cleaned, r\",\", \".\")\n",
        "    return df.withColumn(colname, cleaned.cast(to_type))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Fixe Spalten für deine Dateien"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# Fix: Spalten aus deinen CSVs\n",
        "# ---------------------------\n",
        "\n",
        "# Verkehr.csv\n",
        "TRAFFIC_YEAR_COL  = \"YEAR\"\n",
        "TRAFFIC_VALUE_COL = \"ROAD_TRAFFIC\"\n",
        "\n",
        "# Schadstoff.csv\n",
        "AIR_REGION_COL    = \"Region\"\n",
        "AIR_YEAR_COL      = \"Jahr\"\n",
        "AIR_POLLUTANT_COL = \"Schadstoff\"\n",
        "AIR_VALUE_COL     = \"Werte\"   # nach trimmen heißt es \"Werte\"\n",
        "\n",
        "TARGET_REGION = \"Wien\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Verkehr vorbereiten (YEAR int, ROAD_TRAFFIC double, Region='Wien')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "traffic = traffic_raw\n",
        "\n",
        "traffic = traffic.withColumn(TRAFFIC_YEAR_COL, F.col(TRAFFIC_YEAR_COL).cast(\"int\"))\n",
        "traffic = cast_de_number(traffic, TRAFFIC_VALUE_COL, \"double\")\n",
        "\n",
        "# Verkehr ist laut dir ohnehin Wien -> Region-Spalte setzen\n",
        "traffic = traffic.withColumn(\"Region\", F.lit(TARGET_REGION))\n",
        "\n",
        "traffic.select(TRAFFIC_YEAR_COL, \"Region\", TRAFFIC_VALUE_COL).show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Schadstoffe vorbereiten (Region=Wien, Jahr int, Werte double)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "air = air_raw\n",
        "\n",
        "air = air.withColumn(AIR_YEAR_COL, F.col(AIR_YEAR_COL).cast(\"int\"))\n",
        "air = air.filter(F.trim(F.col(AIR_REGION_COL)) == TARGET_REGION)\n",
        "\n",
        "air = cast_de_number(air, AIR_VALUE_COL, \"double\")\n",
        "\n",
        "air.select(AIR_REGION_COL, AIR_YEAR_COL, AIR_POLLUTANT_COL, AIR_VALUE_COL).show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9) Aggregation pro Jahr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Verkehr pro Jahr (falls mehrere Zeilen pro Jahr vorhanden sind: avg)\n",
        "traffic_year = (traffic\n",
        "    .groupBy(TRAFFIC_YEAR_COL, \"Region\")\n",
        "    .agg(F.avg(F.col(TRAFFIC_VALUE_COL)).alias(\"traffic_road_traffic_avg\"))\n",
        ")\n",
        "\n",
        "traffic_year.orderBy(TRAFFIC_YEAR_COL).show(30, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Schadstoffe pro Jahr & Schadstoff (avg)\n",
        "air_year = (air\n",
        "    .groupBy(AIR_YEAR_COL, AIR_POLLUTANT_COL)\n",
        "    .agg(F.avg(F.col(AIR_VALUE_COL)).alias(\"poll_value_avg\"))\n",
        ")\n",
        "\n",
        "air_year.orderBy(AIR_YEAR_COL, AIR_POLLUTANT_COL).show(30, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Pivot: pro Jahr eine Zeile, pro Schadstoff eine Spalte"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "air_year_pivot = (air_year\n",
        "    .groupBy(AIR_YEAR_COL)\n",
        "    .pivot(AIR_POLLUTANT_COL)\n",
        "    .agg(F.first(\"poll_value_avg\"))\n",
        ")\n",
        "\n",
        "air_year_pivot.orderBy(AIR_YEAR_COL).show(30, truncate=False)\n",
        "print(\"Pivot columns:\", air_year_pivot.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Join über Jahr (left: alle Schadstoff-Jahre behalten)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "joined = (air_year_pivot\n",
        "    .join(\n",
        "        traffic_year.withColumnRenamed(TRAFFIC_YEAR_COL, \"YEAR_join\"),\n",
        "        air_year_pivot[AIR_YEAR_COL] == F.col(\"YEAR_join\"),\n",
        "        how=\"left\"\n",
        "    )\n",
        "    .drop(\"YEAR_join\")\n",
        ")\n",
        "\n",
        "joined.orderBy(AIR_YEAR_COL).show(50, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Quick-Checks: welche Jahre fehlen im Verkehr?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Jahre in Schadstoffen (Wien) ohne Verkehrseintrag\n",
        "missing_traffic_years = (joined\n",
        "    .filter(F.col(\"traffic_road_traffic_avg\").isNull())\n",
        "    .select(AIR_YEAR_COL)\n",
        "    .orderBy(AIR_YEAR_COL))\n",
        "\n",
        "missing_traffic_years.show(200, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Spark ML (Regression) – Gerüst\n",
        "\n",
        "Wir sagen **einen Schadstoff** (Label) aus dem Traffic-Feature voraus.\n",
        "\n",
        "Du musst nur:\n",
        "- `LABEL_COL` auf eine Pivot-Spalte setzen (exakt wie im Pivot, z.B. `\"NO2\"` – je nachdem wie es in deinen Daten heißt)\n",
        "- optional fehlende Traffic-Jahre imputen (z.B. 0.0) oder Zeilen droppen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import RandomForestRegressor, LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ---------------------------\n",
        "# HIER ANPASSEN\n",
        "# ---------------------------\n",
        "\n",
        "# Beispiel: setze hier einen existierenden Schadstoff-Spaltennamen aus dem Pivot:\n",
        "# LABEL_COL = \"NO2\"  # <-- nur Beispiel\n",
        "LABEL_COL = None\n",
        "\n",
        "# Features: fürs Erste nur der Traffic (du kannst später weitere Features ergänzen)\n",
        "FEATURE_COLS = [\"traffic_road_traffic_avg\"]\n",
        "\n",
        "# Option 1: fehlende Traffic-Werte auf 0 setzen (nur fürs schnelle Testen!)\n",
        "IMPUTE_MISSING_TRAFFIC_WITH_ZERO = True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if IMPUTE_MISSING_TRAFFIC_WITH_ZERO:\n",
        "    model_df = joined.fillna({\"traffic_road_traffic_avg\": 0.0})\n",
        "else:\n",
        "    model_df = joined\n",
        "\n",
        "print(\"Spalten im joined:\", model_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "if LABEL_COL is None:\n",
        "    print(\"⚠️ Bitte LABEL_COL setzen. Verfügbare Schadstoff-Spalten (Pivot):\")\n",
        "    # Pivot-Spalten sind alle außer Jahr + traffic feature\n",
        "    pivot_cols = [c for c in model_df.columns if c not in [AIR_YEAR_COL, \"traffic_road_traffic_avg\"]]\n",
        "    print(pivot_cols)\n",
        "else:\n",
        "    data = model_df.select([AIR_YEAR_COL, LABEL_COL] + FEATURE_COLS).dropna(subset=[LABEL_COL] + FEATURE_COLS)\n",
        "\n",
        "    train, test = data.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "    assembler = VectorAssembler(inputCols=FEATURE_COLS, outputCol=\"features\")\n",
        "    model = RandomForestRegressor(featuresCol=\"features\", labelCol=LABEL_COL, numTrees=200, maxDepth=8)\n",
        "\n",
        "    pipeline = Pipeline(stages=[assembler, model])\n",
        "    fitted = pipeline.fit(train)\n",
        "\n",
        "    preds = fitted.transform(test)\n",
        "\n",
        "    rmse = RegressionEvaluator(labelCol=LABEL_COL, predictionCol=\"prediction\", metricName=\"rmse\").evaluate(preds)\n",
        "    r2 = RegressionEvaluator(labelCol=LABEL_COL, predictionCol=\"prediction\", metricName=\"r2\").evaluate(preds)\n",
        "\n",
        "    print(\"✅ RMSE:\", rmse)\n",
        "    print(\"✅ R2:\", r2)\n",
        "\n",
        "    preds.select(AIR_YEAR_COL, LABEL_COL, \"prediction\").orderBy(AIR_YEAR_COL).show(200, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14) Nächste sinnvolle Erweiterungen\n",
        "- Mehr Traffic-Features nutzen (z.B. pro District aggregieren, SCWR_CALC etc.)\n",
        "- Lag-Feature: Verkehr Jahr-1, Jahr-2 (Spark Window)\n",
        "- Multi-Output: pro Schadstoff ein Modell oder ein Multi-Target Ansatz (außerhalb Spark ML Standard)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}